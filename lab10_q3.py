# -*- coding: utf-8 -*-
"""Lab10_Q3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pZDgBMdSDr5WNcUFn2JL_cXXQHO7Appp

Purpose: To explore importance sampling as a method for computing integrals of divergent functions.

Author: Ben Campbell
"""

import numpy as np
import numpy.random as rand
import matplotlib.pyplot as plt

# Part A

#Define the integrand
def integrand(x): return x**(-1/2) / (1 + np.exp(x))

# integration parameters:

N = 10000 # number of points to sample

# define integration methods

# Mean Value Method:

def MVM(integrand, a, b, N):
  '''integrand function must be able to take arrays'''
  samples = rand.uniform(a, b, N) # sample points on the interval of integration
  values = integrand(samples) # sample values of the integrand
  avg_integrand = np.sum(values) / float(N) # estimate the average value of the integrand: thus we can use this to approximate the integral with area of a rectangle
  return avg_integrand * (b-a) # return the area of the rectangle

# importance sampling method:

def ISM(integrand, a, b, N): #weight, a, b, N):
  '''integrand and weight functions must be able to take arrays
  Weight function must satisfy w(x) > 0 for all x
  although not required; the normalization of the weights is sometimes desireable according to some of the sources I have seen
  We need to know the anti-derivative of the weight function and it must not yield a divergent integral. Thus the use of this method is somewhat limited'''
  # draw sample point with distrobution given by the weight function
  samples = rand.uniform(a, b, N) # sample points on the interval of integration
  samples = ((samples-a)/(b-a))**2 *(b-a) + a # sample points are transformed to be given by the weight PDF.
  # I got lazy, and just used the weights for the specific case that we will need.
  summation = np.sum( integrand(samples) * 2*samples**(1/2) )
  return summation/float(N) # chance of rolling 0 exacly is so low that we need not worry about division by zero

# hit-miss - just to see how it compares in the tests

def HMM(integrand,a,b,L_bound,U_bound,N):
  '''integrand function must be able to take arrays'''
  A = (b-a) * (U_bound - L_bound) # area of the bounding box
  samples_x = rand.uniform(a, b, N) # sample points on the interval of integration
  samples_y = rand.uniform(U_bound, L_bound, N) # sample points on the y-axis
  #plt.plot(samples_x, samples_y, 'o')
  #plt.plot(np.sort(samples_x),integrand(np.sort(samples_x)))
  #plt.show()

  #taken together, the above give random coordinates w/in the bounding box.
  num_hits = 0
  for i in range(N):
    # we want to determine if we are between the function and the x-axis so we need to know if the integrand is above or below the x-axis
    if integrand(samples_x[i]) >= 0: # then integrand is above x-axis
      if integrand(samples_x[i]) >= samples_y[i] and samples_y[i] >= 0: # then we hit the area:
        num_hits += 1
      else: # then we miss
        continue # do nothing
    else: # then integrand is below x-axis
      if integrand(samples_x[i]) <= samples_y[i] and samples_y[i] <= 0: # then we hit the area:
        num_hits += 1
      else: # then we miss
        continue # do nothing
  return num_hits/N * A

# test with a known function
test = lambda x: np.sin(x)
# the integral of the test from 0 to pi should be 2
print(MVM(test,0,np.pi,1000000))
#print(ISM(test,lambda x: 1,0,np.pi,1000000)) # not very usefull for this test case
print(HMM(test,0,np.pi,0,1,1000000))

# run the integrations

mean_values = []
import_values = []
for _ in range(100):
  mean_values.append(MVM(integrand,0,1,N))
  import_values.append(ISM(integrand,0,1,N))

#print(mean_values)
#print(import_values)

# mean_value_method histogram
plt.hist(mean_values, 10, range=[0.8, 0.88],rwidth=0.9)
plt.title(r"Mean value method approximation of $\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
plt.xlabel(r"$\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
plt.ylabel("Number of occurences")
plt.show()

# importance_sampling_method histogram
#import_values = np.array(import_values)
plt.hist(import_values, 10, range=[0.8, 0.88],rwidth=0.9)
plt.title(r"Mean value method approximation of $\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
plt.xlabel(r"$\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
plt.ylabel("Number of occurences")
plt.show()

fig, axes = plt.subplots(1,2,figsize=(10,5))

ax_M, ax_I = axes

ax_M.hist(mean_values, 10, range=[0.8, 0.88], rwidth=0.9)
ax_M.set_title("Mean value method estimation\n" + r"of $\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
ax_M.set_ylabel("Number of occurences")
ax_M.set_xlabel(r"$\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
ax_I.hist(import_values, 10, range=[0.8, 0.88], rwidth=0.9)
ax_I.set_title("Importance sampling method\n" + r"estimation of $\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")
ax_I.set_xlabel(r"$\int_0^1 \frac{x^{-1/2}}{1+e^x} ~dx$")

plt.show()

# exact solution
import sympy as sp
'''x = sp.symbols("x")
integrand = sp.sympify("x**(-1/2) / (1 + exp(x))")
sp.integrate(integrand, (x,0,1))''' # cannot be done analytically

# part b

def integrand_b(x): return np.exp(-2*np.abs(x-5))

def ISM_b(integrand, a, b, N):
  '''integrand and weight functions must be able to take arrays
  Weight function must satisfy w(x) > 0 for all x
  although not required; the normalization of the weights is sometimes desireable according to some of the sources I have seen
  We need to know the anti-derivative of the weight function and it must not yield a divergent integral. Thus the use of this method is somewhat limited'''
  # draw sample point with distrobution given by the weight function
  samples = rand.normal(5.,1.,N) # sample points distrobuted according to the weight PDF
  # I got lazy, and just used the weights for the specific case that we will need.
  summation = np.sum( integrand(samples) / ( np.exp(-(samples-5.)**2. / 2) / np.sqrt(2*np.pi) ) )
  return summation/float(N) # chance of rolling 0 exacly is so low that we need not worry about division by zero

# plot the integrand
t = np.linspace(0,10,N)
plt.plot(t,integrand_b(t))
plt.title("plot of the integrand $e^{-2|x-5|}$")
plt.xlabel("$x$")
plt.ylabel("$f(x)$")
plt.show()

# compute integrals 100 times with both methods
mean_values_b = []
import_values_b = []
for _ in range(100):
  mean_values_b.append(MVM(integrand_b,0,10,N))
  import_values_b.append(ISM_b(integrand_b,0,10,N))

print(np.average(mean_values_b))
print(np.average(import_values_b))

# histogram of the integrals

fig, axes = plt.subplots(1,2,figsize=(10,5))

ax_M, ax_I = axes

ax_M.hist(mean_values_b, 10, rwidth=0.9)
ax_M.set_title("Mean value method estimation\nof $\int_{0}^{10} \exp(-2|x-5|) ~dx$")
ax_M.set_ylabel("Number of occurences")
ax_M.set_xlabel("$\int_{0}^{10} \exp(-2|x-5|) ~dx$")
ax_I.hist(import_values_b, 10, rwidth=0.9)
ax_I.set_title("Importance sampling method\nestimation of $\int_{0}^{10} \exp(-2|x-5|) ~dx$")
ax_I.set_title("Importance sampling method\nestimation of $\int_{0}^{10} \exp(-2|x-5|) ~dx$")
ax_I.set_xlabel("$\int_{0}^{10} \exp(-2|x-5|) ~dx$")

fig.subplots_adjust(wspace=0.3)

plt.show()

#exact value
x = sp.symbols("x")
integrand = sp.exp(-2*sp.Abs(x-5))
v = sp.integrate(integrand, (x,0,10))
print(v.evalf())
v

